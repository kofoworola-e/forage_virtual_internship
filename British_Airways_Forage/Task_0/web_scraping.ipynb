{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPLIqrXmdNzs"
      },
      "source": [
        "## Web scraping and analysis\n",
        "\n",
        "This Jupyter notebook includes some code for web scraping. I used `BeautifulSoup` to collect the data from the web. Once the data has been collected it is saved into a local `.csv` file for further analysis.\n",
        "\n",
        "### Scraping data from Skytrax\n",
        "\n",
        "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
        "\n",
        "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8fbTbiOvdN0_"
      },
      "outputs": [],
      "source": [
        "# Importing Web scraping and Data manipulation libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Misc\n",
        "import time\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E1ABW21_dN1C",
        "outputId": "f8fccd40-047c-461f-c5a1-b00d4f14d068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping page 1\n",
            "   ---> 100 total reviews\n",
            "Scraping page 2\n",
            "   ---> 200 total reviews\n",
            "Scraping page 3\n",
            "   ---> 300 total reviews\n",
            "Scraping page 4\n",
            "   ---> 400 total reviews\n",
            "Scraping page 5\n",
            "   ---> 500 total reviews\n",
            "Scraping page 6\n",
            "   ---> 600 total reviews\n",
            "Scraping page 7\n",
            "   ---> 700 total reviews\n",
            "Scraping page 8\n",
            "   ---> 800 total reviews\n",
            "Scraping page 9\n",
            "   ---> 900 total reviews\n",
            "Scraping page 10\n",
            "   ---> 1000 total reviews\n",
            "Scraping page 11\n",
            "   ---> 1100 total reviews\n",
            "Scraping page 12\n",
            "   ---> 1200 total reviews\n",
            "Scraping page 13\n",
            "   ---> 1300 total reviews\n",
            "Scraping page 14\n",
            "   ---> 1400 total reviews\n",
            "Scraping page 15\n",
            "   ---> 1500 total reviews\n",
            "Scraping page 16\n",
            "   ---> 1600 total reviews\n",
            "Scraping page 17\n",
            "   ---> 1700 total reviews\n",
            "Scraping page 18\n",
            "   ---> 1800 total reviews\n",
            "Scraping page 19\n",
            "   ---> 1900 total reviews\n",
            "Scraping page 20\n",
            "   ---> 2000 total reviews\n",
            "Scraping page 21\n",
            "   ---> 2100 total reviews\n",
            "Scraping page 22\n",
            "   ---> 2200 total reviews\n",
            "Scraping page 23\n",
            "   ---> 2300 total reviews\n",
            "Scraping page 24\n",
            "   ---> 2400 total reviews\n",
            "Scraping page 25\n",
            "   ---> 2500 total reviews\n",
            "Scraping page 26\n",
            "   ---> 2600 total reviews\n",
            "Scraping page 27\n",
            "   ---> 2700 total reviews\n",
            "Scraping page 28\n",
            "   ---> 2800 total reviews\n",
            "Scraping page 29\n",
            "   ---> 2900 total reviews\n",
            "Scraping page 30\n",
            "   ---> 3000 total reviews\n",
            "Scraping page 31\n",
            "   ---> 3100 total reviews\n",
            "Scraping page 32\n",
            "   ---> 3200 total reviews\n",
            "Scraping page 33\n",
            "   ---> 3300 total reviews\n",
            "Scraping page 34\n",
            "   ---> 3400 total reviews\n",
            "Scraping page 35\n",
            "   ---> 3500 total reviews\n",
            "Scraping page 36\n",
            "   ---> 3600 total reviews\n",
            "Scraping page 37\n",
            "   ---> 3700 total reviews\n",
            "Scraping page 38\n",
            "   ---> 3800 total reviews\n",
            "Scraping page 39\n",
            "   ---> 3900 total reviews\n",
            "Scraping page 40\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 41\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 42\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 43\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 44\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 45\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 46\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 47\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 48\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 49\n",
            "   ---> 3949 total reviews\n",
            "Scraping page 50\n",
            "   ---> 3949 total reviews\n"
          ]
        }
      ],
      "source": [
        "# This code block scrapes reviews from the British Airways page on AirlineQuality\n",
        "# The reviews are paginated, and we will scrape multiple pages to collect all reviews\n",
        "\n",
        "# Set the base URL and pagination parameters\n",
        "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
        "pages = 50\n",
        "page_size = 100\n",
        "\n",
        "reviews = []      # The reviews are stored in a list and will be converted to a DataFrame at the end\n",
        "\n",
        "for i in range(1, pages + 1):\n",
        "\n",
        "    print(f\"Scraping page {i}\")\n",
        "\n",
        "    # Create URL to collect links from paginated data\n",
        "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
        "\n",
        "    # Collect HTML data from this page\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Parse content\n",
        "    content = response.content\n",
        "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
        "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
        "        reviews.append(para.get_text())\n",
        "\n",
        "    print(f\"   ---> {len(reviews)} total reviews\") # Print the number of reviews collected after each page\n",
        "    time.sleep(1)  # Sleep for 1 second to avoid overwhelming the server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YoLsYt8sdN1F"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"reviews\"] = reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "pANL3-RigYup",
        "outputId": "f70bfe05-d8aa-4615-f444-87bb7a878004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Not Verified |  Decided to use point to upgrade to business after visiting family in the UK. I have to say British Airways Business Class was up there with the best of them. Comfortable seating, great service from the crew and with a smile, and great food. On the whole I found the experience comfortable and worth the points upgrade and will consider flying them again.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['reviews'].loc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base directory = location of the current script or notebook\n",
        "base_dir = Path().resolve()\n",
        "\n",
        "data_dir = base_dir / \"data\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Then save the file\n",
        "raw_reviews_path = data_dir / \"british_airways_reviews.csv\"\n",
        "df.to_csv(raw_reviews_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ba-forage",
      "language": "python",
      "name": "ba-forage"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
